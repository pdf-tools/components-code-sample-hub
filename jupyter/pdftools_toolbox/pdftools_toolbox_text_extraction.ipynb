{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "836b124a-8045-4763-afac-90b624d3abd4",
      "metadata": {
          "id": "2d1e4bfd-7ab8-498d-a849-f50536dc1987"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pdf-tools/components-code-sample-hub/blob/main/jupyter/pdftools_toolbox/pdftools_toolbox_text_extraction.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1272a92a-134b-4871-82f3-a3f962d1fdc8",
      "metadata": {
          "id": "e57c5776-a294-436b-830f-9a6604acbb92"
      },
      "outputs": [],
      "source": [
        "%pip install https://pdftools-public-downloads-production.s3.eu-west-1.amazonaws.com/productkits/PDFSDKXT/latest/pdftools_toolbox-latest.tar.gz\n",
        "%pip install ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df7504f0-aeb5-4add-9ed2-a5ab67386381",
      "metadata": {
          "id": "3e2d151d-a004-4231-b703-14b30cb690e3"
      },
      "source": [
        "# Extract all text from PDF\n",
        "Write text from PDF page by page to console. Determine\n",
        "heuristically if two text fragments belong to the same\n",
        "word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64f361f3-c9d3-4486-93f1-18467c7a71e7",
      "metadata": {
          "id": "e5c24675-9465-4769-bfa3-dee4d75c1d47"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "from pdftools_toolbox.pdf import Document\n",
        "from pdftools_toolbox.pdf.content import ContentExtractor, Text, UngroupingSelection, TextElement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f43ff61d-233d-436f-8c0b-43b72ede27b4",
      "metadata": {
          "id": "2bba3a95-f72e-46f9-980e-17b7fbcd76d0"
      },
      "outputs": [],
      "source": [
        "# Download a file from a given URL and save it to the local system\n",
        "def prepare_file(url: str, path: str):\n",
        "    import requests\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    with open(path, 'wb') as f:\n",
        "        f.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e0203f1-db85-421c-a91d-27d8235496c8",
      "metadata": {
          "id": "7bcf0e7b-fcd4-4bfb-9d83-2bc8759f0729"
      },
      "outputs": [],
      "source": [
        "# Set input arguments\n",
        "input_url = 'https://pdftools-public-downloads-production.s3.eu-west-1.amazonaws.com/samples/testfiles/InvoiceNone.pdf'\n",
        "input_file_path = 'InvoiceNone.pdf'\n",
        "prepare_file(input_url, input_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd9ae2e2-bff4-46a2-a9de-edc6fd00cc7a",
      "metadata": {
          "id": "4c43b69b-9188-4eb7-84f4-a7f22cf6e29f"
      },
      "outputs": [],
      "source": [
        "def write_text(text: Text):\n",
        "    \"\"\"Reconstruct text heuristically from text fragments.\"\"\"\n",
        "    text_part = []\n",
        "\n",
        "    # Write all text fragments\n",
        "    # Determine heuristically if there is a space between two text fragments\n",
        "    for i_fragment, curr_fragment in enumerate(text):\n",
        "        if i_fragment == 0:\n",
        "            text_part.append(curr_fragment.text)\n",
        "        else:\n",
        "            last_fragment = text[i_fragment - 1]\n",
        "\n",
        "            # Determine if there's a space between fragments\n",
        "            if (curr_fragment.character_spacing != last_fragment.character_spacing or\n",
        "                curr_fragment.font_size != last_fragment.font_size or\n",
        "                curr_fragment.horizontal_scaling != last_fragment.horizontal_scaling or\n",
        "                curr_fragment.rise != last_fragment.rise or\n",
        "                curr_fragment.word_spacing != last_fragment.word_spacing):\n",
        "                text_part.append(f\" {curr_fragment.text}\")\n",
        "            else:\n",
        "                current_bot_left = curr_fragment.transform.transform_rectangle(curr_fragment.bounding_box).bottom_left\n",
        "                before_bot_right = last_fragment.transform.transform_rectangle(last_fragment.bounding_box).bottom_right\n",
        "\n",
        "                if (before_bot_right.x < current_bot_left.x - 0.7 * curr_fragment.font_size or\n",
        "                    before_bot_right.y < current_bot_left.y - 0.1 * curr_fragment.font_size or\n",
        "                    current_bot_left.y < before_bot_right.y - 0.1 * curr_fragment.font_size):\n",
        "                    text_part.append(f\" {curr_fragment.text}\")\n",
        "                else:\n",
        "                    text_part.append(curr_fragment.text)\n",
        "\n",
        "    print(\"\".join(text_part))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "904cb11b-9598-4388-8f2f-cd069bf16941",
      "metadata": {
          "id": "306d1a44-9531-4d58-a5e3-9b2ad79d9e9c"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    # Set and check license key. If the license key is not valid, an exception is thrown.\n",
        "    from pdftools_toolbox.sdk import Sdk\n",
        "    Sdk.initialize(\"INSERT-LICENSE-KEY\", None)\n",

        "\n",
        "    # Open input document\n",
        "    with open(input_file_path, \"rb\") as in_stream:\n",
        "        with Document.open(in_stream, None) as in_doc:\n",
        "            page_number = 1\n",
        "    \n",
        "            # Process each page\n",
        "            for in_page in in_doc.pages:\n",
        "                print(f\"==========\nPage: {page_number}\n==========\")\n",
        "    \n",
        "                extractor = ContentExtractor(in_page.content)\n",
        "                extractor.ungrouping = UngroupingSelection.ALL\n",
        "    \n",
        "                # Iterate over all content elements and only process text elements\n",
        "                for element in extractor:\n",
        "                    if isinstance(element, TextElement):\n",
        "                        write_text(element.text)\n",
        "                page_number += 1\n",

        "\n",
        "    print(\"Execution successful.\")\n",

        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}