{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1439732c-732b-4db8-9238-8709e29f9e26",
      "metadata": {
          "id": "94206099-5866-4dcc-b9cf-40ae1f104649"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pdf-tools/components-code-sample-hub/blob/main/jupyter/pdftools_toolbox/pdftools_toolbox_text_extraction.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5569c701-8525-41cd-9441-a3b69051e53d",
      "metadata": {
          "id": "d488534f-1886-4f33-9a9d-243b1331d552"
      },
      "outputs": [],
      "source": [
        "%pip install https://pdftools-public-downloads-production.s3.eu-west-1.amazonaws.com/productkits/PDFSDKXT/latest/pdftools_toolbox-latest.tar.gz\n",
        "%pip install ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f373f3d1-1865-4e02-983e-c2de9f946e39",
      "metadata": {
          "id": "434bd3c3-26d3-416a-ad90-74972b9cd90a"
      },
      "source": [
        "# Extract all text from PDF\n",
        "Write text from PDF page by page to console. Determine\n",
        "heuristically if two text fragments belong to the same\n",
        "word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1f90edc-ee2b-4643-b5ad-a21e3514cec7",
      "metadata": {
          "id": "8db8da44-c267-4bd3-acee-f4ce6b2ee661"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "from pdftools_toolbox.pdf import Document\n",
        "from pdftools_toolbox.pdf.content import ContentExtractor, Text, UngroupingSelection, TextElement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "383fe1d3-f169-4081-8cef-38bc6d837318",
      "metadata": {
          "id": "7c9467ad-5bc0-41d1-8c4f-598afbd93661"
      },
      "outputs": [],
      "source": [
        "# Download a file from a given URL and save it to the local system\n",
        "def prepare_file(url: str, path: str):\n",
        "    import requests\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    with open(path, 'wb') as f:\n",
        "        f.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d56161d-99b7-4f88-9e7a-12f532ca0527",
      "metadata": {
          "id": "8e7b2c16-f81a-4ae3-a723-756c7d48874e"
      },
      "outputs": [],
      "source": [
        "# Set input arguments\n",
        "input_url = 'https://pdftools-public-downloads-production.s3.eu-west-1.amazonaws.com/samples/testfiles/InvoiceNone.pdf'\n",
        "input_file_path = 'InvoiceNone.pdf'\n",
        "prepare_file(input_url, input_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4541042-9018-4568-9dcd-0ccc8b58665e",
      "metadata": {
          "id": "43490128-e777-4930-ac60-fc2cbce57d2e"
      },
      "outputs": [],
      "source": [
        "def write_text(text: Text):\n",
        "    \"\"\"Reconstruct text heuristically from text fragments.\"\"\"\n",
        "    text_part = []\n",
        "\n",
        "    # Write all text fragments\n",
        "    # Determine heuristically if there is a space between two text fragments\n",
        "    for i_fragment, curr_fragment in enumerate(text):\n",
        "        if i_fragment == 0:\n",
        "            text_part.append(curr_fragment.text)\n",
        "        else:\n",
        "            last_fragment = text[i_fragment - 1]\n",
        "\n",
        "            # Determine if there's a space between fragments\n",
        "            if (curr_fragment.character_spacing != last_fragment.character_spacing or\n",
        "                curr_fragment.font_size != last_fragment.font_size or\n",
        "                curr_fragment.horizontal_scaling != last_fragment.horizontal_scaling or\n",
        "                curr_fragment.rise != last_fragment.rise or\n",
        "                curr_fragment.word_spacing != last_fragment.word_spacing):\n",
        "                text_part.append(f\" {curr_fragment.text}\")\n",
        "            else:\n",
        "                current_bot_left = curr_fragment.transform.transform_rectangle(curr_fragment.bounding_box).bottom_left\n",
        "                before_bot_right = last_fragment.transform.transform_rectangle(last_fragment.bounding_box).bottom_right\n",
        "\n",
        "                if (before_bot_right.x < current_bot_left.x - 0.7 * curr_fragment.font_size or\n",
        "                    before_bot_right.y < current_bot_left.y - 0.1 * curr_fragment.font_size or\n",
        "                    current_bot_left.y < before_bot_right.y - 0.1 * curr_fragment.font_size):\n",
        "                    text_part.append(f\" {curr_fragment.text}\")\n",
        "                else:\n",
        "                    text_part.append(curr_fragment.text)\n",
        "\n",
        "    print(\"\".join(text_part))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b432d0-be6a-4e06-b2b6-e7e54e8168f8",
      "metadata": {
          "id": "a0119bdb-c894-46be-90e2-8500da6f0087"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    # Set and check license key. If the license key is not valid, an exception is thrown.\n",
        "    from pdftools_toolbox.sdk import Sdk\n",
        "    Sdk.initialize(\"<PDFSDK,V1,MGAASQD6L2JMQHL54PK08RQX8GG4SS0M8DAHVPH0VMP3NB8R9DUK>\", None)\n",

        "\n",
        "    # Open input document\n",
        "    with open(input_file_path, \"rb\") as in_stream:\n",
        "        with Document.open(in_stream, None) as in_doc:\n",
        "            page_number = 1\n",
        "    \n",
        "            # Process each page\n",
        "            for in_page in in_doc.pages:\n",
        "                print(f\"==========\nPage: {page_number}\n==========\")\n",
        "    \n",
        "                extractor = ContentExtractor(in_page.content)\n",
        "                extractor.ungrouping = UngroupingSelection.ALL\n",
        "    \n",
        "                # Iterate over all content elements and only process text elements\n",
        "                for element in extractor:\n",
        "                    if isinstance(element, TextElement):\n",
        "                        write_text(element.text)\n",
        "                page_number += 1\n",

        "\n",
        "    print(\"Execution successful.\")\n",

        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}