{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ff2d1908-f6ba-48a2-a944-baf837f22c83",
      "metadata": {
          "id": "2641859e-ce81-42b7-af34-6602d3f3d3b8"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pdf-tools/components-code-sample-hub/blob/main/jupyter/pdftools_toolbox/pdftools_toolbox_text_extraction.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75ce18a5-ca72-4769-9105-9ced8e6f5c3b",
      "metadata": {
          "id": "e179b927-13c9-4af4-b8e6-e37d5e817378"
      },
      "outputs": [],
      "source": [
        "%pip install https://pdftools-public-downloads-production.s3.eu-west-1.amazonaws.com/productkits/PDFSDKXT/latest/pdftools_toolbox-latest.tar.gz\n",
        "%pip install ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c7449f4-6648-4630-ad12-c28f43b438a0",
      "metadata": {
          "id": "2fc7578f-196e-4104-95ed-d3c0a88ff7e9"
      },
      "source": [
        "# Extract all text from PDF\n",
        "Write text from PDF page by page to console. Determine\n",
        "heuristically if two text fragments belong to the same\n",
        "word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d02be75-1eca-4f5f-91dc-4d5ef48bd98a",
      "metadata": {
          "id": "a05c68db-10c2-4b47-aa01-04480d3b7dd6"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "from pdftools_toolbox.pdf import Document\n",
        "from pdftools_toolbox.pdf.content import ContentExtractor, Text, UngroupingSelection, TextElement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b552e25-c1cd-4a9d-9767-f478284bbd51",
      "metadata": {
          "id": "2aae7a55-7fa9-4e80-826a-b97736116fcf"
      },
      "outputs": [],
      "source": [
        "# Download a file from a given URL and save it to the local system\n",
        "def prepare_file(url: str, path: str):\n",
        "    import requests\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    with open(path, 'wb') as f:\n",
        "        f.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e07cb76c-642c-4299-a5ea-1874064fdea8",
      "metadata": {
          "id": "7601565f-17cb-432f-b63e-23788079ebb1"
      },
      "outputs": [],
      "source": [
        "# Set input arguments\n",
        "input_url = 'https://pdftools-public-downloads-production.s3.eu-west-1.amazonaws.com/samples/testfiles/InvoiceNone.pdf'\n",
        "input_file_path = 'InvoiceNone.pdf'\n",
        "prepare_file(input_url, input_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebf8437e-946d-4b4f-a88f-29936716ed3b",
      "metadata": {
          "id": "33b06f04-6490-4e98-8db1-2c36632a695f"
      },
      "outputs": [],
      "source": [
        "def write_text(text: Text):\n",
        "    \"\"\"Reconstruct text heuristically from text fragments.\"\"\"\n",
        "    text_part = []\n",
        "\n",
        "    # Write all text fragments\n",
        "    # Determine heuristically if there is a space between two text fragments\n",
        "    for i_fragment, curr_fragment in enumerate(text):\n",
        "        if i_fragment == 0:\n",
        "            text_part.append(curr_fragment.text)\n",
        "        else:\n",
        "            last_fragment = text[i_fragment - 1]\n",
        "\n",
        "            # Determine if there's a space between fragments\n",
        "            if (curr_fragment.character_spacing != last_fragment.character_spacing or\n",
        "                curr_fragment.font_size != last_fragment.font_size or\n",
        "                curr_fragment.horizontal_scaling != last_fragment.horizontal_scaling or\n",
        "                curr_fragment.rise != last_fragment.rise or\n",
        "                curr_fragment.word_spacing != last_fragment.word_spacing):\n",
        "                text_part.append(f\" {curr_fragment.text}\")\n",
        "            else:\n",
        "                current_bot_left = curr_fragment.transform.transform_rectangle(curr_fragment.bounding_box).bottom_left\n",
        "                before_bot_right = last_fragment.transform.transform_rectangle(last_fragment.bounding_box).bottom_right\n",
        "\n",
        "                if (before_bot_right.x < current_bot_left.x - 0.7 * curr_fragment.font_size or\n",
        "                    before_bot_right.y < current_bot_left.y - 0.1 * curr_fragment.font_size or\n",
        "                    current_bot_left.y < before_bot_right.y - 0.1 * curr_fragment.font_size):\n",
        "                    text_part.append(f\" {curr_fragment.text}\")\n",
        "                else:\n",
        "                    text_part.append(curr_fragment.text)\n",
        "\n",
        "    print(\"\".join(text_part))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff6ddfe2-e74b-45ee-847f-0f8695770471",
      "metadata": {
          "id": "ca568abb-53e3-4d0a-9791-f40efec665b7"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    # Set and check license key. If the license key is not valid, an exception is thrown.\n",
        "    from pdftools_toolbox.sdk import Sdk\n",
        "    Sdk.initialize(\"INSERT-LICENSE-KEY\", None)\n",

        "\n",
        "    # Open input document\n",
        "    with open(input_file_path, \"rb\") as in_stream:\n",
        "        with Document.open(in_stream, None) as in_doc:\n",
        "            page_number = 1\n",
        "    \n",
        "            # Process each page\n",
        "            for in_page in in_doc.pages:\n",
        "                print(f\"==========\\nPage: {page_number}\\n==========\")\n",
        "    \n",
        "                extractor = ContentExtractor(in_page.content)\n",
        "                extractor.ungrouping = UngroupingSelection.ALL\n",
        "    \n",
        "                # Iterate over all content elements and only process text elements\n",
        "                for element in extractor:\n",
        "                    if isinstance(element, TextElement):\n",
        "                        write_text(element.text)\n",
        "                page_number += 1\n",

        "\n",
        "    print(\"Execution successful.\")\n",

        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}